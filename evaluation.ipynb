{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import *\n",
    "from utils import SpatialTransform, load_data, CoordsImageTest\n",
    "from INRMorph import INRMorph\n",
    "import pandas as pd\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_wandb_logger():\n",
    "    try:\n",
    "        with open('logger_name.txt', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            if lines:\n",
    "                logger_name = lines[-1].strip()\n",
    "            else:\n",
    "                logger_name = None\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file 'logger_name.txt' does not exist.\")\n",
    "        logger_name = None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        logger_name = None\n",
    "        \n",
    "    run = wandb.init(\n",
    "        project=\"INRMorph\",\n",
    "        name=\"visualizations_\"+logger_name\n",
    "        )\n",
    "    return run, logger_name\n",
    "\n",
    "\n",
    "def jacobian_determinanat(coords, deformation_field):\n",
    "    jac = compute_jacobian_matrix(coords, deformation_field)\n",
    "    return torch.det(jac)\n",
    "\n",
    "        \n",
    "\n",
    "def compute_jacobian_matrix(coords, deformation_field):\n",
    "\n",
    "    dim = coords.shape[1]\n",
    "    # print(\"in jac\", coords.shape, deformation_field.shape, dim)\n",
    "    jacobian_matrix = torch.zeros(coords.shape[0], dim, dim)\n",
    "\n",
    "    for i in range(dim):\n",
    "\n",
    "        jacobian_matrix[:, i, :] = gradient(coords, deformation_field[:, i])\n",
    "        # print(\"jacobian matrix\", jacobian_matrix.shape)\n",
    "    return jacobian_matrix        \n",
    "\n",
    "    \n",
    "def gradient(coords, output, grad_outputs=None):\n",
    "    # print(\"in grad\", coords.shape, output.shape)\n",
    "\n",
    "    grad_outputs = torch.ones_like(output)\n",
    " \n",
    "    grad = torch.autograd.grad(output, [coords], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "\n",
    "    return grad         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = SpatialTransform()\n",
    "validation_batch_size = 1\n",
    "spatial_reg = 0.1\n",
    "temporal_reg = 0.1\n",
    "observed_time = [0, 13, 14, 24]\n",
    "time = [0, 1, 2, 5, 7, 10, 12, 13, 14, 16, 18, 20, 22, 24, 27] #0, 13, 14, 24\n",
    "time = torch.tensor(time, device=device)\n",
    "normalized_time_points = time/12\n",
    "patch_size = 1250\n",
    "project_name = \"INRMorph\"\n",
    "# batch_size = 13520000\n",
    "\n",
    "imagepath = \"dataset/ad/005_S_0814/resampled/\"\n",
    "maskpath = \"dataset_copy/affine_registered/masks/\"\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"INRMorph\"\n",
    "I0 = load_data(imagepath + \"I0.nii\")\n",
    "\n",
    "I0_mask = load_data(maskpath + \"I0_fsl_mask.nii.gz\")\n",
    "\n",
    "image_vector = CoordsImageTest(I0.shape, scale_factor = 1)\n",
    "test_generator = DataLoader(dataset = image_vector, batch_size=patch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "#load model and artifact\n",
    "run, logger_name = set_wandb_logger()\n",
    "print(\"Testing for run with model name: \", logger_name)\n",
    "model = INRMorph(I0, I0, patch_size, spatial_reg, temporal_reg, 4, \"siren\", \"NCC\", \"finite_difference\", \"L2\",  normalized_time_points, observed_time).to(device)\n",
    "artifact = run.use_artifact(f'aishalawal/INRMorph/{logger_name}:best', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "model.load_state_dict(torch.load(artifact_dir + \"/model.ckpt\")[\"state_dict\"])\n",
    "model.eval()\n",
    "print(model)\n",
    "\n",
    "print(\"Number of parameters\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "print(\"Model successfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_time = [0, 13, 14, 24]\n",
    "time = [0, 1, 2, 5, 7, 10, 12, 13, 14, 16, 18, 20, 22, 24, 30] \n",
    "stack_total_deformation_field = []\n",
    "stack_total_jac_det = []\n",
    "stack_tdf = []\n",
    "stack_moved_images = []\n",
    "for selected_time in time:\n",
    "    \n",
    "    selected_time_normalised = torch.tensor(selected_time/12, device=device) \n",
    "\n",
    "    for k, coords in enumerate(test_generator):\n",
    "        coords = coords.squeeze().to(device, dtype=torch.float32).requires_grad_(True)\n",
    "        displacement_vector = model.test_step(coords, selected_time_normalised).squeeze().to(device)\n",
    "        deformation_field = torch.add(displacement_vector, coords)\n",
    "\n",
    "        #compute jacobian determinant batchwise\n",
    "        jac_det = jacobian_determinanat(coords, deformation_field) #shape is batch_size\n",
    "\n",
    "        coords = coords.cpu().detach()\n",
    "        deformation_field = deformation_field.cpu().detach()\n",
    "        jac_det = jac_det.cpu().detach()\n",
    "        \n",
    "        if k==0:\n",
    "\n",
    "            total_jac_det = jac_det\n",
    "            total_deformation_field = deformation_field\n",
    "        else:\n",
    "            total_jac_det = torch.cat((total_jac_det, jac_det))\n",
    "            total_deformation_field = torch.cat((total_deformation_field, deformation_field), 0)\n",
    "\n",
    "    total_deformation_field = total_deformation_field.view(-1, 3).unsqueeze(0)\n",
    "    stack_total_deformation_field.append(total_deformation_field)\n",
    "    moved = transform.trilinear_interpolation(total_deformation_field.to(device), I0).view(I0.shape)  \n",
    "    stack_moved_images.append(moved.cpu().numpy().squeeze())\n",
    "\n",
    "    stack_total_jac_det.append(total_jac_det.view(I0.shape))\n",
    "    stack_tdf.append(total_deformation_field.view(*I0.shape,3))\n",
    "    print(f\"Time step {selected_time} done\")\n",
    "I0 = I0.cpu().numpy()\n",
    "I0_mask = I0_mask.cpu().numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copies\n",
    "stack_total_jac_det_copy = stack_total_jac_det.copy()\n",
    "stack_tdf_copy = stack_tdf.copy()\n",
    "stack_moved_images_copy = stack_moved_images.copy()\n",
    "stack_total_deformation_field_copy = stack_total_deformation_field.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising residuals\n",
    "\n",
    "\n",
    "def image_masking(img, mask, tdf = False):\n",
    "    rows, cols = np.where(mask > 0)\n",
    "    x1, y1 = np.min(rows), np.min(cols)\n",
    "    x2, y2 = np.max(rows), np.max(cols)\n",
    "    \n",
    "    if tdf == True:\n",
    "        masked_image = img[x1-25:x2+20, y1:y2+35, :]\n",
    "    else:\n",
    "        masked_image = img[x1-25:x2+20, y1:y2+35]\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "num_slice = 150\n",
    "image_mask_2d = I0_mask[num_slice, :, :]\n",
    "I0_2d = I0[num_slice, :, :]\n",
    "masked_I0 = image_masking(I0_2d, image_mask_2d, False)\n",
    "video_images = []\n",
    "video_titles = []\n",
    "for idx, selected_time in enumerate(time):\n",
    "    if selected_time in observed_time:\n",
    "        idx = observed_time.index(selected_time)\n",
    "        It = load_data(imagepath + f\"I{idx}.nii\")\n",
    "        # It_mask = load_data(maskpath + f\"I{idx}_fsl_mask.nii.gz\")\n",
    "    else: \n",
    "        It =  torch.zeros_like(torch.tensor(I0))\n",
    "        # It_mask = torch.zeros_like(torch.tensor(I0_mask))\n",
    "\n",
    "    It = It.cpu().numpy()\n",
    "    # It_mask = It_mask.cpu().numpy()\n",
    "\n",
    "    It_2d = It[num_slice, :, :]\n",
    "    moved_2d = stack_moved_images[idx][num_slice, :, :]\n",
    "    tdf_2d = stack_tdf[idx][num_slice, :, :].cpu().numpy()\n",
    "    plot_jac_det_2d = stack_total_jac_det[idx][num_slice, :, :].cpu().numpy()\n",
    "    masked_It = image_masking(It_2d, image_mask_2d, False)\n",
    "\n",
    "    masked_moved = image_masking(moved_2d, image_mask_2d, False)\n",
    "    masked_tdf = image_masking(tdf_2d, image_mask_2d, True )\n",
    "    masked_jac_det = image_masking(plot_jac_det_2d, image_mask_2d, False)\n",
    "\n",
    "    residual = masked_moved - masked_It if selected_time in observed_time else masked_It\n",
    "    \n",
    "    \n",
    "    images = [masked_I0, masked_It, masked_moved,  residual , masked_tdf[..., 0]] \n",
    "    # titles = [r'Baseline $I_0$', r'Observed $I_t={}$'.format(selected_time), r'$I_t\\' (I_0 \\circ \\phi_t={})$'.format(selected_time), 'It\\'-It', 'flow']\n",
    "    titles = [\n",
    "    r'Baseline $I_0$', \n",
    "    r'Observed $I_{t=' + str(selected_time) + '}$', \n",
    "    r\"$I_{t}' = (I_0 \\circ \\phi_{t=\" + str(selected_time) + \"})$\", \n",
    "    r\"$I_{t}' - I_t$\", \n",
    "    'flow'\n",
    "    ]\n",
    "    video_images.append(images)\n",
    "    video_titles.append(titles)\n",
    "    ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);\n",
    "\n",
    "    wandb.log({\"Transformed images\": [wandb.Image(image, caption=title) for image, title in zip(images, titles)]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATION |J| MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from monai-> https://github.com/Project-MONAI/tutorials/blob/main/deep_atlas/utils.py\n",
    "\n",
    "\n",
    "def preview_image(jacobian_det, mask, I0, selected_time, normalize_by=\"volume\", cmap=None, figsize=(12, 12), threshold=None):\n",
    "    \"\"\"\n",
    "    Display three orthogonal slices of the given 3D image and the corresponding I0 slices.\n",
    "\n",
    "    jacobian_det is assumed to be of shape (H,W,D)\n",
    "\n",
    "    If a number is provided for threshold, then pixels for which the value\n",
    "    is below the threshold will be shown in red\n",
    "    \"\"\"\n",
    "    if normalize_by == \"slice\":\n",
    "        vmin = None\n",
    "        vmax = None\n",
    "        \n",
    "    elif normalize_by == \"volume\":\n",
    "        vmin = jacobian_det.min().item()\n",
    "        # vmax = jacobian_det.max().item()\n",
    "        vmax = jacobian_det.max().item()\n",
    "\n",
    "    else:\n",
    "        raise (ValueError(f\"Invalid value '{normalize_by}' given for normalize_by\"))\n",
    "\n",
    "    # half-way slices\n",
    "    rows, cols, dep = np.where(mask > 0)\n",
    "    x1, x2, = min(rows), max(rows)\n",
    "    y1, y2 = min(cols), max(cols)\n",
    "    z1, z2 = min(dep), max(dep)\n",
    "\n",
    "    x, y, z = np.array(jacobian_det.shape) // 2\n",
    "    jac_det_slices = (jacobian_det[x, :, :], jacobian_det[:, y, :], jacobian_det[:, :, z])\n",
    "\n",
    "    I0_slices = (I0[x, :, :], I0[:, y, :], I0[:, :, z])\n",
    "\n",
    "    # jac_det_slices = (jacobian_det[x, y1:y2, z1:z2], jacobian_det[x, y1:y2, z1:z2], jacobian_det[x1:x2, y1:y2, z])\n",
    "\n",
    "    # I0_slices = (I0[x, y1:y2, z1:z2], I0[x1:x2, y, z1:z2], I0[x1:x2, y1:y2, z])\n",
    "    fig, axs = plt.subplots(2, 3, figsize=figsize)\n",
    "\n",
    "    for i, (img, I0_slice) in enumerate(zip(jac_det_slices, I0_slices)):\n",
    "        ax = axs[0, i]\n",
    "        # ax.axis(\"off\")\n",
    "        gg = ax.imshow(img, origin=\"lower\", vmin=vmin, vmax=vmax, cmap=\"viridis\")\n",
    "        if threshold is not None:\n",
    "            red = np.zeros(img.shape + (4,))  # RGBA array\n",
    "            red[img <= threshold] = [1, 0, 0, 1]\n",
    "            ax.imshow(red, origin=\"upper\")\n",
    "\n",
    "        # Add colorbar for the image slice\n",
    "        cbar = fig.colorbar(gg, ax=ax, fraction=0.046, pad=0.05)\n",
    "        # cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "        ax = axs[1, i]\n",
    "        ax.axis(\"off\")\n",
    "        hh = ax.imshow(I0_slice, origin=\"upper\", cmap=\"gray\")\n",
    "        # hh = ax.imshow(I0_slice, origin=\"upper\", cmap=cmap)\n",
    "\n",
    "\n",
    "        # Add colorbar for the I0 slice\n",
    "        cbar = fig.colorbar(hh, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.ax.tick_params(labelsize=8)\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        text = f\"\"\"\n",
    "        Time: {selected_time}\n",
    "        Number of folds: {(det<=0).sum()}\n",
    "        Number of expansion: {(det>1).sum()}\n",
    "        Number of contraction: {((det > 0) & (det < 1)).sum()}\n",
    "        Number of voxels without change: {(det==1).sum()}\n",
    "        |J| min, max and mean: {float(det.min().item()):.2f}, {float(det.max().item()):.2f}, {float(det.mean().item()):.3f}\n",
    "        \n",
    "        \"\"\"\n",
    "    ax.set_facecolor(\"yellow\")\n",
    "    plt.figtext(0.7, 0.90, text, ha=\"left\", fontsize=10, bbox={\"facecolor\": \"white\", \"edgecolor\": \"white\", \"alpha\": 0, \"pad\": 5, \"linewidth\": 3})\n",
    "    wandb.log({\"Jacobian Maps\": wandb.Image(fig)})\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "video_jacobian_maps = []\n",
    "for idx, selected_time in enumerate(time):\n",
    "    det = stack_total_jac_det[idx]\n",
    "    fig =preview_image(det, I0_mask, stack_moved_images[idx], selected_time, normalize_by=\"slice\", threshold=0)\n",
    "    video_jacobian_maps.append(fig)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATING SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warp the labbeled I0 with deformation field to compute dice between moved_I0 and It_seg\n",
    "\n",
    "\n",
    "def load_seg_data(path: str) -> torch.tensor:\n",
    "    data = np.array(nib.load(path).get_fdata())\n",
    "    data = torch.tensor(data, device=device, dtype=torch.float32)\n",
    "    return data\n",
    "\n",
    "stack_moved_seg = []\n",
    "video_images_seg = []\n",
    "video_titles_seg = []\n",
    "I0_seg = load_seg_data(\"dataset/ad/005_S_0814/labels/I0_seg.nii\")\n",
    "z = 150\n",
    "image_mask_2d_seg = I0_mask[:, z, :] \n",
    "I0_2d_seg = I0_seg[:, z, :].cpu().numpy()\n",
    "\n",
    "\n",
    "for idx, selected_time in enumerate(time):\n",
    "    if selected_time in observed_time:\n",
    "        idx = observed_time.index(selected_time)\n",
    "        It_seg = load_seg_data(f\"dataset/ad/005_S_0814/labels/I{idx}_seg.nii\")\n",
    "    else: \n",
    "        It_seg =  torch.zeros_like(torch.tensor(I0_seg))\n",
    "    \n",
    "    moved_seg = transform.nearest_neighbor_interpolation(stack_total_deformation_field[idx].to(device), I0_seg).view(I0_seg.shape)  \n",
    "    stack_moved_seg.append(moved_seg.cpu().numpy().squeeze())\n",
    "\n",
    "\n",
    "    It_2d_seg = It_seg[:, z, :].cpu().numpy()\n",
    "    moved_2d_label = moved_seg[:, z, :].cpu().numpy()\n",
    "\n",
    "    residual = moved_2d_label-It_2d_seg if selected_time in observed_time else It_2d_seg\n",
    "    \n",
    "    tdf_2d = stack_tdf[idx][:, z, :].cpu().numpy()\n",
    "    masked_tdf = image_masking(tdf_2d, image_mask_2d, True )\n",
    "\n",
    "    images = [I0_2d_seg, It_2d_seg, moved_2d_label,  residual, masked_tdf[..., 1]] \n",
    "    titles = [\n",
    "        r'Baseline $I_0$', \n",
    "        r'Observed $S(I_{t=' + str(selected_time) + '})$', \n",
    "        r\"$S(I_{t}') = S(I_0)  \\circ \\phi_{t=\" + str(selected_time) + \"}$\", \n",
    "        r\"$S(I_{t}') - S(I_t)$\",\n",
    "        'flow'\n",
    "    ]\n",
    "    video_images_seg.append(images)\n",
    "    video_titles_seg.append(titles)\n",
    "    \n",
    "    ne.plot.slices(images, titles=titles, do_colorbars=True,  cmaps=['viridis']);\n",
    "\n",
    "    wandb.log({\"Transformed segmentation maps\": [wandb.Image(image, caption=title) for image, title in zip(images, titles)]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATING MEAN |J| MASKS AND SAVING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str) -> torch.tensor: #256, 256, 166\n",
    "    data = np.array(nib.load(path).get_fdata())\n",
    "    data = torch.tensor(data, device=device, dtype=torch.float32)\n",
    "    return data\n",
    "\n",
    "structures = [\n",
    "    \"lateral_ventricle\",\n",
    "    \"thalamus\",\n",
    "    \"caudate\",\n",
    "    \"putamen\",\n",
    "    \"pallidum\",\n",
    "    \"hippocampus\",\n",
    "    \"amygdala\"\n",
    "]\n",
    "\n",
    "left_structures = [4, 10, 11, 12, 13, 17, 18]\n",
    "right_structures = [43, 49, 50, 51, 52, 53, 54]\n",
    "result_path = \"result/\"+logger_name+\".csv\"\n",
    "\n",
    "def dice_score(label1, label2):\n",
    "    intersection = np.sum(label1[label1 > 0] == label2[label1 > 0])\n",
    "    dice = (2 * intersection) / (np.sum(label1) + np.sum(label2))\n",
    "    return dice\n",
    "\n",
    "def combine_labels(img1, img2, selected_time, state = \"Dice Score\"):\n",
    "\n",
    "    total_dice = 0\n",
    "    structure_dice = {}\n",
    "\n",
    "    for i, structure in enumerate(structures):\n",
    "        img1_combined = np.where(np.isin(img1, [left_structures[i], right_structures[i]]), 1, 0)\n",
    "        img2_combined = np.where(np.isin(img2, [left_structures[i], right_structures[i]]), 1, 0)\n",
    "        dice = dice_score(img1_combined, img2_combined)\n",
    "        structure_dice[structure] = dice\n",
    "        # print(f\"{structure}: {dice:.4f}\")\n",
    "        total_dice+=dice\n",
    "    if selected_time in observed_time:\n",
    "        print(f\"Time = {selected_time}, {state} : {total_dice/len(structures)}\")\n",
    "    return structure_dice, total_dice/len(structures)\n",
    "\n",
    "def compute_mean_jac_det(moved_label):\n",
    "    mean_jacobian_determinants = {}\n",
    "    for i, structure in enumerate(structures):\n",
    "        mask =  np.where(np.isin(moved_label, [left_structures[i], right_structures[i]]), 1, 0)\n",
    "        \n",
    "        jacobian_values = det[mask > 0]\n",
    "        mean_jacobian_determinants[structure] = jacobian_values.mean().item()\n",
    "    return mean_jacobian_determinants\n",
    "\n",
    "\n",
    "for selected_time in time:\n",
    "    selected_time_normalised = selected_time/12\n",
    "    if selected_time in observed_time:\n",
    "        idx = observed_time.index(selected_time)\n",
    "        It_seg = load_data(f\"dataset/ad/005_S_0814/labels/I{idx}_seg.nii\")\n",
    "    else: \n",
    "        It_seg =  torch.zeros_like(I0_seg)\n",
    "    It_seg = It_seg.cpu().numpy()\n",
    "         \n",
    "    structure_dice_affine, total_dice_affine = combine_labels(I0_seg.cpu().numpy(), It_seg, selected_time,\"Dice between I0 and It (affine)\")\n",
    "    structure_dice_target_predicted, total_dice_target_predicted = combine_labels(stack_moved_seg[idx], It_seg, selected_time, \"Dice at It and It\\'(target vs predicted)\")\n",
    "\n",
    "    det = stack_total_jac_det[idx]\n",
    "    mean_jac_det = compute_mean_jac_det(stack_moved_seg[idx])\n",
    "    number_of_folds = (det<=0).sum().item()\n",
    "    number_of_expansions = (det>1).sum().item()\n",
    "    number_of_contractions= ((det > 0) & (det < 1)).sum().item()\n",
    "    no_volume_change =  (det==1).sum().item()\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        with open(result_path, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"subjectID\", \"selected_time\", \"structure\", \"structure_mean_jac_det\", \"jac_det_mean\",\"jac_det_min\", \"jac_det_max\",\"structure_dice_affine\", \"structure_dice_target_predicted\",\n",
    "                            \"total_dice_affine\", \"total_dice_target_predicted\", \"number_of_folds\", \"number_of_expansions\", \"number_of_contractions\", \"no_volume_change\"])\n",
    "\n",
    "    try:\n",
    "\n",
    "        with open(result_path, 'a') as f:\n",
    "            if selected_time not in time: # when interpolating or extrapolating\n",
    "                for i, structure in enumerate(structures):\n",
    "                    writer = csv.writer(f)\n",
    "                    rows = [imagepath.split(\"/\")[2], selected_time, structure, mean_jac_det[structure], det.mean().item(),\n",
    "                        det.min().item(), det.max().item(), np.nan, np.nan, \n",
    "                        np.nan, np.nan, number_of_folds, number_of_expansions, number_of_contractions, no_volume_change]\n",
    "                    writer.writerow(rows)\n",
    "                    \n",
    "            else:\n",
    "                for i, structure in enumerate(structures):\n",
    "                    writer = csv.writer(f)\n",
    "                    rows = [imagepath.split(\"/\")[2], selected_time, structure, mean_jac_det[structure], det.mean().item(),\n",
    "                        det.min().item(), det.max().item(), structure_dice_affine[structure], structure_dice_target_predicted[structure], \n",
    "                        total_dice_affine, total_dice_target_predicted, number_of_folds, number_of_expansions, number_of_contractions, no_volume_change]\n",
    "                    writer.writerow(rows)\n",
    "\n",
    "            \n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not write to file {result_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting graphs\n",
    "df = pd.read_csv(result_path)\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Group the data by structure and plot the line plot\n",
    "for structure in df['structure'].unique():\n",
    "    structure_data = df[df['structure'] == structure]\n",
    "    ax.plot(structure_data['selected_time'], structure_data['structure_mean_jac_det'], label=structure, marker='*', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Time Point')\n",
    "ax.set_ylabel('mean |J|')\n",
    "ax.set_title('Mean |J| over Time')\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.grid()\n",
    "plt.show()\n",
    "wandb.log({\"Mean Jacobian Determinant Over time\": wandb.Image(fig)})\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "affine_label_added = False\n",
    "nonlinear_label_added = False\n",
    "\n",
    "for time_point in df['selected_time'].unique():\n",
    "    if time_point in observed_time:\n",
    "        time_point_data = df[df['selected_time'] == time_point]\n",
    "        # Plot affine line\n",
    "        ax.plot(time_point, time_point_data['total_dice_affine'].mean(), \n",
    "                marker='*', linestyle='-', color='blue', label=\"Affine\" if not affine_label_added else \"\")\n",
    "        affine_label_added = True\n",
    "        ax.plot(time_point, time_point_data['total_dice_target_predicted'].mean(), marker='*', linestyle='-', color='orange', label=\"Non-linear\" if not nonlinear_label_added else \"\")\n",
    "        nonlinear_label_added = True\n",
    "ax.set_xlabel('Time Point')\n",
    "ax.set_ylabel('Dice Cooefficient')\n",
    "ax.set_title('Comparing affine and non-linear Dice Coefficient over Time')\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()\n",
    "wandb.log({\"Comparing affine and non-linear Dice Coefficient over Time\": wandb.Image(fig)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GENERATING JACOBIAN MAP VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "#initialise function to display the first frame\n",
    "def init():\n",
    "    ax.clear()  #clear the axis\n",
    "    ax.axis('off') \n",
    "    return []\n",
    "\n",
    "#update function for each frame\n",
    "def update(frame):\n",
    "    ax.clear()  #clear previous frame\n",
    "    ax.axis('off')\n",
    "\n",
    "    #render the figure to a canvas\n",
    "    canvas = FigureCanvas(video_jacobian_maps[frame])\n",
    "    canvas.draw()\n",
    "    \n",
    "    #convert canvas to a numpy array\n",
    "    img = np.frombuffer(canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    img = img.reshape(canvas.get_width_height()[::-1] + (3,))  #reshape to (height, width, 3)\n",
    "\n",
    "    ax.imshow(img)\n",
    "    return []\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(video_jacobian_maps), init_func=init, blit=True, interval=1000)\n",
    "\n",
    "video_filename = 'jacobian_maps_video.mp4'\n",
    "ani.save(video_filename, writer='ffmpeg', fps=1,  codec='vp9', dpi=300)  #1 frame per second\n",
    "\n",
    "wandb.log({\"Jacobian Maps Video\": wandb.Video(video_filename, format=\"mp4\")})\n",
    "\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "# plt.fig(video_jacobian_maps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#number of time points and images per time point\n",
    "num_time_points = len(video_images)\n",
    "num_images = len(video_images[0])\n",
    "\n",
    "#initialize a list to hold the composite images\n",
    "composite_images = []\n",
    "\n",
    "#create individual figures for each time point and store them\n",
    "for t in range(num_time_points):\n",
    "    fig, axs = plt.subplots(2, num_images, figsize=(10, 7))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        axs[0, i].imshow(video_images[t][i], cmap='gray')\n",
    "        axs[0, i].set_title(video_titles[t][i])\n",
    "        axs[0, i].axis('off')\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        axs[1, i].imshow(video_images_seg[t][i], cmap='gray')\n",
    "        axs[1, i].set_title(video_titles_seg[t][i])\n",
    "        axs[1, i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #render the figure to a canvas and convert to a numpy array\n",
    "    canvas = FigureCanvas(fig)\n",
    "    canvas.draw()\n",
    "    \n",
    "    #convert the canvas to a numpy array\n",
    "    img = np.frombuffer(canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    img = img.reshape(canvas.get_width_height()[::-1] + (3,))  #(height, width, 3)\n",
    "    \n",
    "    # Append the image to the list\n",
    "    composite_images.append(img)\n",
    "    plt.close(fig) \n",
    "\n",
    "#create the animation using the stored images\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "def init():\n",
    "    ax.clear()\n",
    "    ax.axis('off')\n",
    "    return []\n",
    "\n",
    "def update(frame):\n",
    "    ax.clear()\n",
    "    ax.axis('off')\n",
    "    ax.imshow(composite_images[frame])\n",
    "    return []\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(composite_images), init_func=init, blit=True, interval=1000)\n",
    "\n",
    "video_filename = 'time_lapse_transition.mp4'\n",
    "ani.save(video_filename, writer='ffmpeg', fps=1, dpi=300, codec='vp9')\n",
    "wandb.log({\"Time Lapse Transition Video\": wandb.Video(video_filename, format=\"mp4\")})\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
